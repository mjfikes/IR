{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "# IPEDS Cohort Clustering Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Author: Matthew Fikes\n",
    "# Modified: 3/16/22\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is set up to find similar IPEDS schools based on a given UNITID. The code will obtain values from IPEDS directly and filter by some of the target school characteristics. Some of the filters are set up to limit data to only 2-year public schools. These are noted with comments in the code and can be altered to find other groups.\n",
    "\n",
    "The code is not entirely automated, the number of clusters should be modified based on the results of the generated dendrograms. Information on reading dendrograms is included where the first chart is generated.\n",
    "\n",
    "This example resulted in exactly 10 schools after some filtering. Your results may vary and you may wish to keep a larger initial cluster and filter it manually by looking at programs offered at the different comparison institutions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_id = int(input(r'Enter your school UNITID from IPEDS (ex. 193283): ')) # replace with UNITID for your school. \n",
    "\n",
    "# these can be found during initial cluster analysis and removed manually via this list. This could probably be automatic\n",
    "# if the first clustering operation removed the smallest cluster before running again.\n",
    "outlier_ids = [] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Gets Directory Data from IPEDS, only return Public 2-year schools'''\n",
    "\n",
    "def getDirectoryData():\n",
    "    \n",
    "    # this goes to the current directory and can be updated on the IPEDS datacenter\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/HD2020.zip'\n",
    "    \n",
    "    # limit to a few fields about identification and institutional characteristics for filtering later\n",
    "    dir_fields = ['UNITID','INSTNM','IALIAS','ADDR','CITY','STABBR','ZIP','OBEREG','OPEID','SECTOR','CONTROL',\n",
    "                  'HLOFFER','LOCALE','INSTCAT','C18BASIC','INSTSIZE','CBSA','CBSATYPE','CSA','COUNTYNM','LONGITUD','LATITUDE']\n",
    "    \n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file not found.\")\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = zipfile.open(zipfile.namelist()[0])\n",
    "    data = pd.read_csv(files,encoding='cp1252')\n",
    "    df = data[dir_fields]\n",
    "    \n",
    "    # Sector filters results to 2-year schools\n",
    "    output = df[(df['SECTOR']==4)]\n",
    "    return(output)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls Fall Enrollment Data from IPEDS Fall Enrollment File A:\n",
    "    Race/ethnicity, gender, attendance status, and level of student\n",
    "    for specified 4-digit year, returns as a Pandas dataframe'''\n",
    "\n",
    "def getFallEnrollment(year):\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/EF{0}A.zip'.format(year)\n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop()) \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "    \n",
    "    # this filters the Fall Enrollment data to \"All students, Undergraduate Total\"\n",
    "    fall_data = data[(data['EFALEVEL']==2)][['UNITID','EFTOTLT']]\n",
    "    fall_data.rename(columns={'EFTOTLT':'FallEnrollment'},inplace=True)\n",
    "    return(fall_data)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls 12-Month Enrollment Data from IPEDS Fall Enrollment File:\n",
    "    12-month unduplicated headcount by race/ethnicity, gender and level of student\n",
    "    for specified 4-digit year, returns as a Pandas dataframe'''\n",
    "\n",
    "def get12MEnrollment(year):\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/EFFY{0}.zip'.format(year)\n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop())\n",
    " \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "    \n",
    "    # limits results to All students, undergraduate total\n",
    "    fte_data = data[(data['EFFYALEV']==2)][['UNITID','EFYTOTLT']]\n",
    "    fte_data.rename(columns={'EFYTOTLT':'LatestFTE'},inplace=True)\n",
    "    return(fte_data)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls Grad Rate Data from IPEDS Fall Enrollment File A:\n",
    "    Race/ethnicity, gender, attendance status, and level of student\n",
    "    for specified 4-digit year, returns as a Pandas dataframe'''\n",
    "\n",
    "def getGradRates(year):\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/GR{0}.zip'.format(year)\n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop())\n",
    " \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "    # COHORT 4 filters to Degree/certif-seeking students 2017 cohort ( 2-yr institution)\n",
    "    # GRTYPE 29 filters to  Degree/certif-seeking students ( 2-yr institution) Adjusted cohort (revised cohort minus exclusions)\n",
    "    fte_data = data[(data['COHORT']==4) & (data['GRTYPE']==29)][['UNITID','GRTOTLT']]\n",
    "    fte_data.rename(columns={'GRTOTLT':'GradRate'},inplace=True)\n",
    "    return(fte_data)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls Fall Enrollment Data from IPEDS Fall Enrollment File A:\n",
    "    Race/ethnicity, gender, attendance status, and level of student\n",
    "    for specified 4-digit year, returns as a Pandas dataframe'''\n",
    "\n",
    "def getFinance(year):\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/F{0}_F1A.zip'.format(year)\n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop())\n",
    " \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "    \n",
    "    # F1B09: Total Operating Revenue\n",
    "    # F1B01: Tutition/Fees as a % of Operating Revenue\n",
    "    # F1B11: State Appropriations as a % of Operating Revenue\n",
    "    # F1N07: Total Expenditures\n",
    "    fin_data = data[['UNITID','F1B09','F1B11','F1B01','F1N07   ']]\n",
    "    fin_data.replace(0,np.nan,inplace=True)\n",
    "    fin_data.dropna(axis=0,how='any',inplace=True)\n",
    "    fin_data['TuitFeePct'] = data['F1B01']/data['F1B09']\n",
    "    fin_data['StAppPct'] = data['F1B11']/data['F1B09']\n",
    "    fin_data.rename(columns={'F1B09':'TotOpRevenue','F1N07   ':'TotalExpend'},inplace=True)\n",
    "    fin_data.drop(['F1B11','F1B01'],axis=1,inplace=True)\n",
    "    return(fin_data)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls Fall Enrollment Data from IPEDS Fall Enrollment File A:\n",
    "    Race/ethnicity, gender, attendance status, and level of student\n",
    "    for specified 4-digit year, returns as a Pandas dataframe'''\n",
    "\n",
    "def getCosts(year):\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/IC{0}_AY.zip'.format(year)\n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop())\n",
    " \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "        \n",
    "    # limits data to in-state tuition and fees and out-of-state tuition and fees\n",
    "    fte_data = data[['UNITID','TUITION2','FEE2','TUITION3','FEE3']]\n",
    "    fte_data.replace('.',np.nan,inplace=True)\n",
    "    fte_data.dropna(axis=0,how='any',inplace=True)\n",
    "    fte_data['In-State'] = fte_data['TUITION2'].astype(int)+fte_data['FEE2'].astype(int)\n",
    "    fte_data['Out-of-State'] =fte_data['TUITION3'].astype(int)+fte_data['FEE3'].astype(int)\n",
    "    \n",
    "    return(fte_data[['UNITID','In-State','Out-of-State']])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pulls Completion Data from IPEDS Completions File C:\n",
    "    Number of students receivign awards/degrees, \n",
    "    by award level and by gender, race/ethnicity and age categories'''\n",
    "\n",
    "def getCompletions(year):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    url = 'https://nces.ed.gov/ipeds/datacenter/data/C{0}_C.zip'.format(year)\n",
    "    \n",
    "    try:\n",
    "        file = urlopen(url)\n",
    "    except:\n",
    "        print(\"Zip file for year {0} not found.\".format(year))\n",
    "        return\n",
    "    zipfile = ZipFile(BytesIO(file.read()))\n",
    "    files = [zipfile.open(file_name) for file_name in zipfile.namelist()]\n",
    "    \n",
    "    if len(files)>1:\n",
    "        user_choice = input(\"Revision found for {0}. Use revised? Y/N: \".format(year))\n",
    "        if user_choice in['Y','y']:\n",
    "            data = pd.read_csv(files.pop())\n",
    " \n",
    "        else:\n",
    "            data = pd.read_csv(files[0])\n",
    "    else:\n",
    "        data = pd.read_csv(files[0])\n",
    "    \n",
    "    # limits to associates degrees and certificates\n",
    "    comp_data = data[(data['AWLEVELC'].isin([2,3,11,12]))][['UNITID','CSTOTLT']].groupby('UNITID').sum().reset_index()\n",
    "    comp_data.rename(columns={'CSTOTLT':'Completions'},inplace=True)\n",
    "    return(comp_data)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in all the data\n",
    "print('Loading data, this may take a moment.')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "directory_df = getDirectoryData()\n",
    "fall_df = getFallEnrollment(2020)\n",
    "fte_df = get12MEnrollment(2020)\n",
    "grad_df = getGradRates(2020)\n",
    "fin_df = getFinance(1920)\n",
    "cost_df = getCosts(2020)\n",
    "comp_df = getCompletions(2020)\n",
    "warnings.filterwarnings(\"default\")\n",
    "print('Load complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    local_c18basic = directory_df[(directory_df['UNITID']==local_id)]['C18BASIC'].values[0]\n",
    "    local_instsize = directory_df[(directory_df['UNITID']==local_id)]['INSTSIZE'].values[0]\n",
    "except:\n",
    "    print('UNITID not found.')\n",
    "    local_id = int(input(r'Enter your school UNITID from IPEDS (ex. 193283): '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This filters initial cluster group to matches with Carnegie 18 Basic classification for local institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_df = directory_df[(directory_df['C18BASIC']==local_c18basic)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "m1 = directory_df[['UNITID']].merge(fall_df,on='UNITID',how='left')\n",
    "m2 = m1.merge(fte_df,on='UNITID',how='left')\n",
    "m3 = m2.merge(grad_df,on='UNITID',how='left')\n",
    "m4 = m3.merge(fin_df,on='UNITID',how='left')\n",
    "m5 = m4.merge(cost_df,on='UNITID',how='left')\n",
    "merged_df = m5.merge(comp_df,on='UNITID',how='left')\n",
    "merged_df.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from data\n",
    "new_df = merged_df[~merged_df.UNITID.isin(outlier_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fieldlist for calculation/normalization\n",
    "val_fields = ['FallEnrollment','LatestFTE','GradRate','TotOpRevenue','TotalExpend','TuitFeePct','StAppPct','In-State','Out-of-State','Completions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = new_df['UNITID']\n",
    "d = pd.DataFrame(preprocessing.normalize(new_df[val_fields],axis=0),columns=val_fields)\n",
    "scaled_df = pd.concat([labels.reset_index(drop=True),d.reset_index(drop=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Clustering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "X_fit = pca.fit_transform(d)\n",
    "X_principal = pd.DataFrame(X_fit)\n",
    "X_principal.columns = ['P1', 'P2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize =(8, 8))\n",
    "plt.title('Visualising the data')\n",
    "Dendrogram = shc.dendrogram((shc.linkage(X_principal, method ='ward')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dendrogram above to find the ideal number of clusters.\n",
    "For instructions on interpreting a dendrogram, check here: \n",
    "\n",
    "https://www.displayr.com/what-is-dendrogram/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac2 = AgglomerativeClustering(n_clusters = 2) # set n_clusters to value from dendrogram above (or custom value for testing)\n",
    "  \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(X_principal['P1'], X_principal['P2'], \n",
    "           c = ac2.fit_predict(X_principal), cmap ='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.concat([labels.reset_index(drop=True),pd.Series(ac2.labels_).reset_index(drop=True)],axis=1)\n",
    "clusters.rename(columns={0:'Cluster'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_clusters = clusters.merge(new_df,on='UNITID')\n",
    "local_cluster = data_w_clusters[(data_w_clusters['UNITID']==local_id)]['Cluster'].values[0]\n",
    "print('Target school is in cluster #',local_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_group = data_w_clusters[(data_w_clusters['Cluster']==local_cluster)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics for initial cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_group.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clusters.groupby('Cluster').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = new_group['UNITID']\n",
    "d2 = pd.DataFrame(preprocessing.normalize(new_group[val_fields],axis=0),columns=val_fields)\n",
    "scaled_df2 = pd.concat([labels2.reset_index(drop=True),d2.reset_index(drop=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Clustering Model again on smaller set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components = 2)\n",
    "X_fit2 = pca.fit_transform(d2)\n",
    "X_principal2 = pd.DataFrame(X_fit2)\n",
    "X_principal2.columns = ['P1', 'P2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize =(8, 8))\n",
    "plt.title('Visualising the data')\n",
    "Dendrogram = shc.dendrogram((shc.linkage(X_principal2, method ='ward')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ac3 = AgglomerativeClustering(n_clusters = 3) # use results from dendrogram above to get n_clusters\n",
    "  \n",
    "# Visualizing the clustering\n",
    "plt.figure(figsize =(6, 6))\n",
    "plt.scatter(X_principal2['P1'], X_principal2['P2'], \n",
    "           c = ac3.fit_predict(X_principal2), cmap ='rainbow')\n",
    "#plt.legend(ac3.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters2 = pd.concat([labels2.reset_index(drop=True),pd.Series(ac3.labels_).reset_index(drop=True)],axis=1)\n",
    "clusters2.rename(columns={0:'NewCluster'},inplace=True)\n",
    "data_clusters = clusters2.merge(new_group,on='UNITID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mv_cluster = data_clusters[(data_clusters['UNITID']==local_id)]['NewCluster'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mv_group = data_clusters[(data_clusters['NewCluster']==new_mv_cluster)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display averages by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_clusters.groupby('NewCluster')[val_fields].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Summary statistics for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mv_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = new_mv_group[['UNITID']].merge(directory_df,on='UNITID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = new_mv_group.merge(directory_df,on='UNITID')\n",
    "full_data.drop(columns=['Cluster','NewCluster'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final custom filtering to limit institution size and locale information to local institution record\n",
    "'LOCALE' variable refers to census designations for the level of urbanization in the area:\n",
    "\n",
    "11 = City: Large: Territory inside an urbanized area and inside a principal city with population of 250,000 or more. \n",
    "\n",
    "12 = City: Midsize: Territory inside an urbanized area and inside a principal city with population less than 250,000 and greater than or equal to 100,000.\n",
    "\n",
    "13 = City: Small: Territory inside an urbanized area and inside a principal city with population less than 100,000.\n",
    "\n",
    "21 = Suburb: Large: Territory outside a principal city and inside an urbanized area with population of 250,000 or more.\n",
    "\n",
    "22 = Suburb: Midsize: Territory outside a principal city and inside an urbanized area with population less than 250,000 and greater than or equal to 100,000.\n",
    "\n",
    "23 = Suburb: Small: Territory outside a principal city and inside an urbanized area with population less than 100,000.\n",
    "\n",
    "31 = Town: Fringe: Territory inside an urban cluster that is less than or equal to 10 miles from an urbanized area.\n",
    "\n",
    "32 = Town: Distant: Territory inside an urban cluster that is more than 10 miles and less than or equal to 35 miles from an urbanized area.\n",
    "\n",
    "33 = Town: Remote: Territory inside an urban cluster that is more than 35 miles of an urbanized area.\n",
    "\n",
    "41 - Rural: Fringe: Census-defined rural territory that is less than or equal to 5 miles from an urbanized area, as well as rural territory that is less than or equal to 2.5 miles from an urban cluster. \n",
    "\n",
    "42 = Rural: Distant: Census-defined rural territory that is more than 5 miles but less than or equal to 25 miles from an urbanized area, as well as rural territory that is more than 2.5 miles but less than or equal to 10 miles from an urban cluster. \n",
    "\n",
    "43 = Rural: Remote: Census-defined rural territory that is more than 25 miles from an urbanized area and is also more than 10 miles from an urban cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = group_data[((group_data['INSTSIZE']==local_instsize))|(group_data['LOCALE'].isin([13,21,22]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output list of USERIDs in new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_cohort = cohort[(cohort['LOCALE'].isin([13,21,22]))]\n",
    "final_cohort['UNITID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output list of schools in new cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_cohort['INSTNM'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export full data for new cluster to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.merge(final_cohort[['UNITID']],on='UNITID',how='inner').to_excel('New Cohort.xlsx',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
